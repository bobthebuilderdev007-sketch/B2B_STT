# Phase‑1 ASR Project — Requirements
# Target Python: **3.11.9** (pin this minor version to avoid breakage)

# --- Core ML (install torch first if you have a GPU) ---
# Install ffmpeg (for video to audio conversion) from github and add ffmpeg/bin into system path
# Example GPU build (CUDA 12.1):
# pip install torch==2.1.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121
# For CPU-only: same command without the index-url.
torch==2.1.0
torchaudio==2.1.0

# --- Speech Recognition & Diarization ---
# Choose one ASR backend. We use OpenAI Whisper by default:
openai-whisper==20231117
# (Optional alternative; comment-in to try it)
# faster-whisper==0.10.0

# pyannote stack
pyannote.audio==3.1.1
pyannote.metrics==3.2.1

# --- Audio/Video & Signal Processing ---
librosa==0.10.1
soundfile==0.12.1
ffmpeg-python==0.2.0
moviepy==1.0.3

# --- Data & Utilities ---
pandas==2.1.4
# numpy pin avoids breaking changes with librosa/scipy wheels on Py3.11
numpy>=1.24.0,<2.0.0
tqdm==4.66.1
python-dotenv==1.0.0
huggingface-hub==0.20.2
transformers>=4.35.0

# --- Evaluation ---
jiwer==3.0.3

# --- Optional (recommended for local dev) ---
ipython>=8.0.0
jupyter>=1.0.0
matplotlib>=3.7.0
seaborn>=0.12.0

# --- Dev Tools (optional) ---
black>=23.0.0
flake8>=6.0.0
pytest>=7.4.0
